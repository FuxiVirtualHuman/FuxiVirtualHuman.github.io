<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>CVPR'23 Skull Restoration, Facial Reconstruction and Expression</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
</head>

<body>  

<div class="container">

  <table border="0" align="center">
    <tr>
      <td width="750" align="center" valign="middle"><h3>CVPR 2023 Tutorial on</h3>
      <span class="title"><h3>Skull Restoration, Facial Reconstruction and Expression</h3></span></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><h3>8:45am - 12:00pm, June 18, 2023</h3></td>
    </tr>
  </table>
 
</div>

</br>

<div class="container">
  <h2>Tutorial Lecturers</h2>
  <br><br>
    <div>
      <div class="instructor">
          <a href="https://people.tamu.edu/~xinli/" >
        <div class="instructorphoto"><img src="photo/xin-li.jpg" alt="" width="200px" height="240px"></div>
        <div>Xin Li<br>Texas A&M University</div>
        </a>
        
        
      </div>

      <div class="instructor">
        <a href="https://www.xu-lan.com/">
            <div class="instructorphoto"><img src="photo/lan-xu.jpg" alt="" width="200px" height="240px"></div>
            <div>Lan Xu<br>ShanghaiTech University</div>
        </a>
         
      </div>

      <div class="instructor">
          <a href="https://dingyu.github.io/">
        <div class="instructorphoto"><img src="photo/yu-ding.jpg" alt="" width="200px" height="240px"></div>
        <div>Yu Ding<br>Netease Fuxi AI Lab</div>
        </a>
       
      </div>

    </div>
    <p></p> 
</div>   

</br>

<div class="container">
  <h2>Overview</h2>
    <div class="overview">
  This tutorial focuses on the problems of reconstructing a 3D model from a fragmented skull or a human face and then generating facial expressions. Faces refer to a specific category of objects with particular patterns of identity and expression that can be leveraged to address general problems of reconstruction and modeling. This tutorial is composed of three parts, including facial reconstruction from skeletal remains, 4D dynamic facial performance with high-quality physically-based textures, and audio-driven talking face generation. We will describe these three parts in more detail as follows.
    <li>
  Face modeling (generation and editing) is a fundamental technique and has broad applications in animation, vision, games, and VR. While recent data-driven face modeling techniques achieved great success, facial geometries are fundamentally governed by its underlying skull and tissue structures. This session covers a forensic task of facial reconstruction from skeletal remains, in which the skull, tissue, and face are all studied together. We will discuss how to model anthropological features, restore fragmented skulls, and reconstruct human faces upon them. Involved feature modeling, correspondence, and constrained face generation and editing techniques are general and can benefit many other computer vision tasks.
    </li>
 
    <li> In the second part, we will then detail state-of-the-art systems and methods to capture 4D dynamic facial performance, which is the foundation for face modeling and rendering with supervised ground truth data. We will consider the hardware design choices for cameras, sensors, lighting, and describe all the steps needed to obtain dynamic facial geometry
along with high-quality physically-based textures, including pore-level diffuse albedo, specular intensity, and normal maps. We will discuss the two traditional and complementary workhorses for recovering facial performances: multi-view stereo and photometric stereo. We will also show how to combine conventional capture pipelines with neural rendering advances to construct neural facial assets. This section also involves the recent trends in combining medical imaging for capturing physically plausible and biologically correct facial performance.    
    </li>
    <li> In the second part, we will then detail state-of-the-art systems and methods to capture 4D dynamic facial performance, which is the foundation for face modeling and rendering with supervised ground truth data. We will consider the hardware design choices for cameras, sensors, lighting, and describe all the steps needed to obtain dynamic facial geometry
along with high-quality physically-based textures, including pore-level diffuse albedo, specular intensity, and normal maps. We will discuss the two traditional and complementary workhorses for recovering facial performances: multi-view stereo and photometric stereo. We will also show how to combine conventional capture pipelines with neural rendering advances to construct neural facial assets. This section also involves the recent trends in combining medical imaging for capturing physically plausible and biologically correct facial performance.    
    </li>
  <ul>
  </ul>
    </div>
</div>

</br>

<div class="container">
  <h2>Schedule</h2>
    <div class="schedule">
      Coming soon
    </div>  
</div>

</br>



<p hidden><script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=LdxpRW9fITesfkHHPmLW9UCycw2sC4Hj-cyY6yuXnlw&cl=ffffff&w=a"></script></p>
<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
